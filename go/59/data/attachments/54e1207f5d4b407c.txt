[35mDEBUG   [0m tests.conftest:conftest.py:43 Running fixture setup: test_id
[35mDEBUG   [0m tests.conftest:conftest.py:49 Running test: test_single_pubsub_topic[/waku/2/rs/0/0] with id: 2024-03-29_14-08-46__7b56f275-6dde-469b-89e5-50bd77754b5b
[35mDEBUG   [0m src.steps.sharding:sharding.py:27 Running fixture setup: relay_setup
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:17 Docker client initialized with image harbor.status.im/wakuorg/nwaku:latest
[35mDEBUG   [0m src.node.waku_node:waku_node.py:50 WakuNode instance initialized with log path ./log/docker/node1_2024-03-29_14-08-46__7b56f275-6dde-469b-89e5-50bd77754b5b__harbor.status.im_wakuorg_nwaku:latest.log
[35mDEBUG   [0m src.steps.sharding:sharding.py:181 Cluster id was resolved to: 0
[35mDEBUG   [0m src.node.waku_node:waku_node.py:54 Starting Node...
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:20 Attempting to create or retrieve network waku
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:23 Network waku already exists
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:80 Generated random external IP 172.18.224.224
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:73 Generated ports ['60789', '60790', '60791', '60792', '60793']
[35mDEBUG   [0m src.node.waku_node:waku_node.py:294 RLN credentials were not set
[32mINFO    [0m src.node.waku_node:waku_node.py:115 RLN credentials not set or credential store not available, starting without RLN
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:47 docker run -i -t -p 60789:60789 -p 60790:60790 -p 60791:60791 -p 60792:60792 -p 60793:60793 harbor.status.im/wakuorg/nwaku:latest --listen-address=0.0.0.0 --rest=true --rest-admin=true --websocket-support=true --log-level=TRACE --rest-relay-cache-capacity=100 --websocket-port=60791 --rest-port=60789 --tcp-port=60790 --discv5-udp-port=60792 --rest-address=0.0.0.0 --nat=extip:172.18.224.224 --peer-exchange=true --discv5-discovery=true --cluster-id=0 --metrics-server=true --metrics-server-address=0.0.0.0 --metrics-server-port=60793 --metrics-logging=true --relay=true --nodekey=30348dd51465150e04a5d9d932c72864c8967f806cce60b5d26afeca1e77eb68 --pubsub-topic=/waku/2/rs/0/0
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:53 docker network connect --ip 172.18.224.224 waku 1fed571515f675d73ece7c0313ea947605b7bdfc52012eb475437790720340fe
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:56 Container started with ID 1fed571515f6. Setting up logs at ./log/docker/node1_2024-03-29_14-08-46__7b56f275-6dde-469b-89e5-50bd77754b5b__harbor.status.im_wakuorg_nwaku:latest.log
[35mDEBUG   [0m src.node.waku_node:waku_node.py:121 Started container from image harbor.status.im/wakuorg/nwaku:latest. REST: 60789
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 1 seconds
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X GET "http://127.0.0.1:60789/debug/v1/info" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'{"listenAddresses":["/ip4/172.18.224.224/tcp/60790/p2p/16Uiu2HAmGNtM2rQ8abySFNhqPDFY4cmfAEpfo9Z9fD3NekoFR2ip","/ip4/172.18.224.224/tcp/60791/ws/p2p/16Uiu2HAmGNtM2rQ8abySFNhqPDFY4cmfAEpfo9Z9fD3NekoFR2ip"],"enrUri":"enr:-LO4QEpUrdHeuKgvUgGMly_FpVInwgH4cl0sRuM8FzUG5lPkD0YPWuOLTJ5SiQzPEeehBrZ-MStPeJzIk6_njN0rCmwBgmlkgnY0gmlwhKwS4OCKbXVsdGlhZGRyc4wACgSsEuDgBu133QOCcnOFAAABAACJc2VjcDI1NmsxoQM3Tqpf5eFn4Jztm4gB0Y0JVSJyxyZsW8QR-QU5DZb-PYN0Y3CC7XaDdWRwgu14hXdha3UyAQ"}'
[32mINFO    [0m src.node.waku_node:waku_node.py:191 REST service is ready !!
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:17 Docker client initialized with image harbor.status.im/wakuorg/go-waku:latest
[35mDEBUG   [0m src.node.waku_node:waku_node.py:50 WakuNode instance initialized with log path ./log/docker/node2_2024-03-29_14-08-46__7b56f275-6dde-469b-89e5-50bd77754b5b__harbor.status.im_wakuorg_go-waku:latest.log
[35mDEBUG   [0m src.steps.sharding:sharding.py:181 Cluster id was resolved to: 0
[35mDEBUG   [0m src.node.waku_node:waku_node.py:54 Starting Node...
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:20 Attempting to create or retrieve network waku
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:23 Network waku already exists
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:80 Generated random external IP 172.18.116.21
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:73 Generated ports ['26606', '26607', '26608', '26609', '26610']
[35mDEBUG   [0m src.node.waku_node:waku_node.py:294 RLN credentials were not set
[32mINFO    [0m src.node.waku_node:waku_node.py:115 RLN credentials not set or credential store not available, starting without RLN
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:47 docker run -i -t -p 26606:26606 -p 26607:26607 -p 26608:26608 -p 26609:26609 -p 26610:26610 harbor.status.im/wakuorg/go-waku:latest --listen-address=0.0.0.0 --rest=true --rest-admin=true --websocket-support=true --log-level=DEBUG --rest-relay-cache-capacity=100 --websocket-port=26608 --rest-port=26606 --tcp-port=26607 --discv5-udp-port=26609 --rest-address=0.0.0.0 --nat=extip:172.18.116.21 --peer-exchange=true --discv5-discovery=true --cluster-id=0 --min-relay-peers-to-publish=1 --rest-filter-cache-capacity=50 --relay=true --discv5-bootstrap-node=enr:-LO4QEpUrdHeuKgvUgGMly_FpVInwgH4cl0sRuM8FzUG5lPkD0YPWuOLTJ5SiQzPEeehBrZ-MStPeJzIk6_njN0rCmwBgmlkgnY0gmlwhKwS4OCKbXVsdGlhZGRyc4wACgSsEuDgBu133QOCcnOFAAABAACJc2VjcDI1NmsxoQM3Tqpf5eFn4Jztm4gB0Y0JVSJyxyZsW8QR-QU5DZb-PYN0Y3CC7XaDdWRwgu14hXdha3UyAQ --pubsub-topic=/waku/2/rs/0/0
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:53 docker network connect --ip 172.18.116.21 waku 3cbc737a2bf60b10c2b5802db89842be888b287ed117f3165b4893f44dd88748
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:56 Container started with ID 3cbc737a2bf6. Setting up logs at ./log/docker/node2_2024-03-29_14-08-46__7b56f275-6dde-469b-89e5-50bd77754b5b__harbor.status.im_wakuorg_go-waku:latest.log
[35mDEBUG   [0m src.node.waku_node:waku_node.py:121 Started container from image harbor.status.im/wakuorg/go-waku:latest. REST: 26606
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 1 seconds
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X GET "http://127.0.0.1:26606/debug/v1/info" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'{"enrUri":"enr:-MW4QJzL-aGzyc9Hhkm6K52od3L1TA5GWPhQgW-S231-dSNQZBXmzfrqVy7hYul4-BIpXoEEqy2N65Y1cSv1pvSpHXmGAY6Kiq8cgmlkgnY0gmlwhKwRAAWKbXVsdGlhZGRyc5gACgSsEQAFBmfw3QMACgR_AAABBmfw3QOCcnOFAAABAACJc2VjcDI1NmsxoQIExySAhJbzvL326_hObaXT3VUzXlHmMzyu5cz3tpuEyoN0Y3CCZ--DdWRwgmfxhXdha3UyAQ","listenAddresses":["/ip4/127.0.0.1/tcp/26607/p2p/16Uiu2HAkukKjVmFXpaadUchxFH3kvKUeEVaYMacGthkmX9KfMB8D","/ip4/127.0.0.1/tcp/26608/ws/p2p/16Uiu2HAkukKjVmFXpaadUchxFH3kvKUeEVaYMacGthkmX9KfMB8D","/ip4/172.17.0.5/tcp/26607/p2p/16Uiu2HAkukKjVmFXpaadUchxFH3kvKUeEVaYMacGthkmX9KfMB8D","/ip4/172.17.0.5/tcp/26608/ws/p2p/16Uiu2HAkukKjVmFXpaadUchxFH3kvKUeEVaYMacGthkmX9KfMB8D"]}'
[32mINFO    [0m src.node.waku_node:waku_node.py:191 REST service is ready !!
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X POST "http://127.0.0.1:60789/relay/v1/subscriptions" -H "Content-Type: application/json" -d '["/waku/2/rs/0/0"]'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'OK'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X POST "http://127.0.0.1:26606/relay/v1/subscriptions" -H "Content-Type: application/json" -d '["/waku/2/rs/0/0"]'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'true'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X POST "http://127.0.0.1:60789/relay/v1/messages/%2Fwaku%2F2%2Frs%2F0%2F0" -H "Content-Type: application/json" -d '{"payload": "U2hhcmRpbmcgd29ya3MhIQ==", "contentTopic": "/myapp/1/latest/proto", "timestamp": '$(date +%s%N)'}'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 0.1 seconds
[35mDEBUG   [0m src.steps.sharding:sharding.py:152 Checking that peer NODE_1:harbor.status.im/wakuorg/nwaku:latest can find the published message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X GET "http://127.0.0.1:60789/relay/v1/messages/%2Fwaku%2F2%2Frs%2F0%2F0" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'[{"payload":"U2hhcmRpbmcgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1711721329453296384,"ephemeral":false}]'
[35mDEBUG   [0m src.steps.sharding:sharding.py:152 Checking that peer NODE_2:harbor.status.im/wakuorg/go-waku:latest can find the published message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X GET "http://127.0.0.1:26606/relay/v1/messages/%2Fwaku%2F2%2Frs%2F0%2F0" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'[{"payload":"U2hhcmRpbmcgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1711721329453296384,"ephemeral":false}]'
[35mDEBUG   [0m tests.conftest:conftest.py:51 Running fixture teardown: test_setup
[35mDEBUG   [0m tests.conftest:conftest.py:75 Running fixture teardown: close_open_nodes
[35mDEBUG   [0m src.node.waku_node:waku_node.py:168 Stopping container with id 1fed571515f6
[35mDEBUG   [0m src.node.waku_node:waku_node.py:171 Container stopped.
[35mDEBUG   [0m src.node.waku_node:waku_node.py:168 Stopping container with id 3cbc737a2bf6
[35mDEBUG   [0m src.node.waku_node:waku_node.py:171 Container stopped.