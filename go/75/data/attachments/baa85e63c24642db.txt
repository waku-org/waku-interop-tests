[35mDEBUG   [0m tests.conftest:conftest.py:43 Running fixture setup: test_id
[35mDEBUG   [0m tests.conftest:conftest.py:49 Running test: test_single_pubsub_topic[/waku/2/rs/8/0] with id: 2024-04-10_03-20-21__83342be0-57c0-4fca-bf52-963115135dac
[35mDEBUG   [0m src.steps.sharding:sharding.py:29 Running fixture setup: sharding_setup
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:17 Docker client initialized with image harbor.status.im/wakuorg/nwaku:latest
[35mDEBUG   [0m src.node.waku_node:waku_node.py:50 WakuNode instance initialized with log path ./log/docker/node1_2024-04-10_03-20-21__83342be0-57c0-4fca-bf52-963115135dac__harbor.status.im_wakuorg_nwaku:latest.log
[35mDEBUG   [0m src.steps.sharding:sharding.py:243 Cluster id was resolved to: 8
[35mDEBUG   [0m src.node.waku_node:waku_node.py:54 Starting Node...
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:20 Attempting to create or retrieve network waku
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:23 Network waku already exists
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:80 Generated random external IP 172.18.3.75
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:73 Generated ports ['14286', '14287', '14288', '14289', '14290']
[35mDEBUG   [0m src.node.waku_node:waku_node.py:294 RLN credentials were not set
[32mINFO    [0m src.node.waku_node:waku_node.py:115 RLN credentials not set or credential store not available, starting without RLN
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:47 docker run -i -t -p 14286:14286 -p 14287:14287 -p 14288:14288 -p 14289:14289 -p 14290:14290 harbor.status.im/wakuorg/nwaku:latest --listen-address=0.0.0.0 --rest=true --rest-admin=true --websocket-support=true --log-level=TRACE --rest-relay-cache-capacity=100 --websocket-port=14288 --rest-port=14286 --tcp-port=14287 --discv5-udp-port=14289 --rest-address=0.0.0.0 --nat=extip:172.18.3.75 --peer-exchange=true --discv5-discovery=true --cluster-id=8 --metrics-server=true --metrics-server-address=0.0.0.0 --metrics-server-port=14290 --metrics-logging=true --relay=true --filter=true --nodekey=30348dd51465150e04a5d9d932c72864c8967f806cce60b5d26afeca1e77eb68 --pubsub-topic=/waku/2/rs/8/0
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:53 docker network connect --ip 172.18.3.75 waku 9a724efca465aaf29fce4fee7e8691687fcbd9066a4050b5ff591dc7d9286622
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:56 Container started with ID 9a724efca465. Setting up logs at ./log/docker/node1_2024-04-10_03-20-21__83342be0-57c0-4fca-bf52-963115135dac__harbor.status.im_wakuorg_nwaku:latest.log
[35mDEBUG   [0m src.node.waku_node:waku_node.py:121 Started container from image harbor.status.im/wakuorg/nwaku:latest. REST: 14286
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 1 seconds
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X GET "http://127.0.0.1:14286/debug/v1/info" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'{"listenAddresses":["/ip4/172.18.3.75/tcp/14287/p2p/16Uiu2HAmGNtM2rQ8abySFNhqPDFY4cmfAEpfo9Z9fD3NekoFR2ip","/ip4/172.18.3.75/tcp/14288/ws/p2p/16Uiu2HAmGNtM2rQ8abySFNhqPDFY4cmfAEpfo9Z9fD3NekoFR2ip"],"enrUri":"enr:-LO4QPv5-Ya5W5HlGEi53WqpmEyxHhHQb_-E7AwWzvF-qEV6FRfI6Kz3m4nG6R8xQ44pdYWm6si4PhPPg4C2EMA8QHUBgmlkgnY0gmlwhKwSA0uKbXVsdGlhZGRyc4wACgSsEgNLBjfQ3QOCcnOFAAgBAACJc2VjcDI1NmsxoQM3Tqpf5eFn4Jztm4gB0Y0JVSJyxyZsW8QR-QU5DZb-PYN0Y3CCN8-DdWRwgjfRhXdha3UyBQ"}'
[32mINFO    [0m src.node.waku_node:waku_node.py:191 REST service is ready !!
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:17 Docker client initialized with image harbor.status.im/wakuorg/go-waku:latest
[35mDEBUG   [0m src.node.waku_node:waku_node.py:50 WakuNode instance initialized with log path ./log/docker/node2_2024-04-10_03-20-21__83342be0-57c0-4fca-bf52-963115135dac__harbor.status.im_wakuorg_go-waku:latest.log
[35mDEBUG   [0m src.steps.sharding:sharding.py:243 Cluster id was resolved to: 8
[35mDEBUG   [0m src.node.waku_node:waku_node.py:54 Starting Node...
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:20 Attempting to create or retrieve network waku
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:23 Network waku already exists
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:80 Generated random external IP 172.18.31.106
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:73 Generated ports ['10678', '10679', '10680', '10681', '10682']
[35mDEBUG   [0m src.node.waku_node:waku_node.py:294 RLN credentials were not set
[32mINFO    [0m src.node.waku_node:waku_node.py:115 RLN credentials not set or credential store not available, starting without RLN
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:47 docker run -i -t -p 10678:10678 -p 10679:10679 -p 10680:10680 -p 10681:10681 -p 10682:10682 harbor.status.im/wakuorg/go-waku:latest --listen-address=0.0.0.0 --rest=true --rest-admin=true --websocket-support=true --log-level=DEBUG --rest-relay-cache-capacity=100 --websocket-port=10680 --rest-port=10678 --tcp-port=10679 --discv5-udp-port=10681 --rest-address=0.0.0.0 --nat=extip:172.18.31.106 --peer-exchange=true --discv5-discovery=true --cluster-id=8 --min-relay-peers-to-publish=1 --rest-filter-cache-capacity=50 --relay=true --discv5-bootstrap-node=enr:-LO4QPv5-Ya5W5HlGEi53WqpmEyxHhHQb_-E7AwWzvF-qEV6FRfI6Kz3m4nG6R8xQ44pdYWm6si4PhPPg4C2EMA8QHUBgmlkgnY0gmlwhKwSA0uKbXVsdGlhZGRyc4wACgSsEgNLBjfQ3QOCcnOFAAgBAACJc2VjcDI1NmsxoQM3Tqpf5eFn4Jztm4gB0Y0JVSJyxyZsW8QR-QU5DZb-PYN0Y3CCN8-DdWRwgjfRhXdha3UyBQ --pubsub-topic=/waku/2/rs/8/0
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:53 docker network connect --ip 172.18.31.106 waku 1186c9b76098d196b7b71c8cf5ce7cd2b841f325a056dd81dc02f1228ff0d655
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:56 Container started with ID 1186c9b76098. Setting up logs at ./log/docker/node2_2024-04-10_03-20-21__83342be0-57c0-4fca-bf52-963115135dac__harbor.status.im_wakuorg_go-waku:latest.log
[35mDEBUG   [0m src.node.waku_node:waku_node.py:121 Started container from image harbor.status.im/wakuorg/go-waku:latest. REST: 10678
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 1 seconds
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X GET "http://127.0.0.1:10678/debug/v1/info" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'{"enrUri":"enr:-MW4QEzuLbRYVMIYuMkXDlty1sx7Gu25hxIaaCnRIabAOxteMrqWaU6o6jnBAvD3lCo7mqoFQyVsOlo06NLO9cZrDGCGAY7GBVofgmlkgnY0gmlwhKwRAAmKbXVsdGlhZGRyc5gACgSsEQAJBim43QMACgR_AAABBim43QOCcnOFAAgBAACJc2VjcDI1NmsxoQJVDhBCCBhA2PjUMTfTYYESbY-3dqPCQ3-WGKs-80qoBIN0Y3CCKbeDdWRwgim5hXdha3UyAQ","listenAddresses":["/ip4/127.0.0.1/tcp/10679/p2p/16Uiu2HAm19h58xeZ99irAFgNjjn5XHvZw941QFD74YhKyTaEkPnK","/ip4/127.0.0.1/tcp/10680/ws/p2p/16Uiu2HAm19h58xeZ99irAFgNjjn5XHvZw941QFD74YhKyTaEkPnK","/ip4/172.17.0.9/tcp/10679/p2p/16Uiu2HAm19h58xeZ99irAFgNjjn5XHvZw941QFD74YhKyTaEkPnK","/ip4/172.17.0.9/tcp/10680/ws/p2p/16Uiu2HAm19h58xeZ99irAFgNjjn5XHvZw941QFD74YhKyTaEkPnK"]}'
[32mINFO    [0m src.node.waku_node:waku_node.py:191 REST service is ready !!
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X POST "http://127.0.0.1:14286/relay/v1/subscriptions" -H "Content-Type: application/json" -d '["/waku/2/rs/8/0"]'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'OK'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X POST "http://127.0.0.1:10678/relay/v1/subscriptions" -H "Content-Type: application/json" -d '["/waku/2/rs/8/0"]'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'true'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X POST "http://127.0.0.1:14286/relay/v1/messages/%2Fwaku%2F2%2Frs%2F8%2F0" -H "Content-Type: application/json" -d '{"payload": "U2hhcmRpbmcgd29ya3MhIQ==", "contentTopic": "/myapp/1/latest/proto", "timestamp": '$(date +%s%N)'}'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 0.1 seconds
[35mDEBUG   [0m src.steps.sharding:sharding.py:176 Checking that peer NODE_1:harbor.status.im/wakuorg/nwaku:latest can find the published message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X GET "http://127.0.0.1:14286/relay/v1/messages/%2Fwaku%2F2%2Frs%2F8%2F0" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'[{"payload":"U2hhcmRpbmcgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1712719224410890240,"ephemeral":false}]'
[35mDEBUG   [0m src.steps.sharding:sharding.py:176 Checking that peer NODE_2:harbor.status.im/wakuorg/go-waku:latest can find the published message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:38 curl -v -X GET "http://127.0.0.1:10678/relay/v1/messages/%2Fwaku%2F2%2Frs%2F8%2F0" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:23 Response status code: 200. Response content: b'[{"payload":"U2hhcmRpbmcgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1712719224410890240,"ephemeral":false}]'
[35mDEBUG   [0m tests.conftest:conftest.py:51 Running fixture teardown: test_setup
[35mDEBUG   [0m tests.conftest:conftest.py:75 Running fixture teardown: close_open_nodes
[35mDEBUG   [0m src.node.waku_node:waku_node.py:168 Stopping container with id 9a724efca465
[35mDEBUG   [0m src.node.waku_node:waku_node.py:171 Container stopped.
[35mDEBUG   [0m src.node.waku_node:waku_node.py:168 Stopping container with id 1186c9b76098
[35mDEBUG   [0m src.node.waku_node:waku_node.py:171 Container stopped.