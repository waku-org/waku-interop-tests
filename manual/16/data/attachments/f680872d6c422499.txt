[35mDEBUG   [0m tests.conftest:conftest.py:51 Running fixture setup: test_id
[35mDEBUG   [0m tests.conftest:conftest.py:57 Running test: test_time_filter_zero_start_end_time with id: 2025-01-17_10-14-57__c6cca51d-ff3f-4661-b808-8a5298fabfd0
[35mDEBUG   [0m src.steps.common:common.py:18 Running fixture setup: common_setup
[35mDEBUG   [0m src.steps.store:store.py:31 Running fixture setup: store_setup
[35mDEBUG   [0m src.steps.store:store.py:39 Running fixture setup: node_setup
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:19 Docker client initialized with image quay.io/wakuorg/nwaku-pr:3244
[35mDEBUG   [0m src.node.waku_node:waku_node.py:85 WakuNode instance initialized with log path ./log/docker/publishing_node1_2025-01-17_10-14-57__c6cca51d-ff3f-4661-b808-8a5298fabfd0__quay.io_wakuorg_nwaku-pr:3244.log
[35mDEBUG   [0m src.node.waku_node:waku_node.py:89 Starting Node...
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:22 Attempting to create or retrieve network waku
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:25 Network waku already exists
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:108 Generated random external IP 172.18.135.23
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:101 Generated ports ['7060', '7061', '7062', '7063', '7064']
[35mDEBUG   [0m src.node.waku_node:waku_node.py:439 RLN credentials were not set
[32mINFO    [0m src.node.waku_node:waku_node.py:168 RLN credentials not set or credential store not available, starting without RLN
[35mDEBUG   [0m src.node.waku_node:waku_node.py:170 Using volumes []
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:49 docker run -i -t -p 7060:7060 -p 7061:7061 -p 7062:7062 -p 7063:7063 -p 7064:7064 quay.io/wakuorg/nwaku-pr:3244 --listen-address=0.0.0.0 --rest=true --rest-admin=true --websocket-support=true --log-level=TRACE --rest-relay-cache-capacity=100 --websocket-port=7062 --rest-port=7060 --tcp-port=7061 --discv5-udp-port=7063 --rest-address=0.0.0.0 --nat=extip:172.18.135.23 --peer-exchange=true --discv5-discovery=true --cluster-id=3 --nodekey=ff537e5e0c2aeaccb9e8fd4fc53f6efcadbaecc0b11fca8447f563ac0efe0acd --shard=0 --metrics-server=true --metrics-server-address=0.0.0.0 --metrics-server-port=7064 --metrics-logging=true --store=true --relay=true
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:55 docker network connect --ip 172.18.135.23 waku 6602cf8673746b0f37e55042ffde7acd633f62cc41e4ccc80f6fbdd973d5fd80
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:58 Container started with ID 6602cf867374. Setting up logs at ./log/docker/publishing_node1_2025-01-17_10-14-57__c6cca51d-ff3f-4661-b808-8a5298fabfd0__quay.io_wakuorg_nwaku-pr:3244.log
[35mDEBUG   [0m src.node.waku_node:waku_node.py:182 Started container from image quay.io/wakuorg/nwaku-pr:3244. REST: 7060
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 1 seconds
[31m[1mERROR   [0m src.node.docker_mananger:docker_mananger.py:89 Max retries reached for container c9ec9d4c527f. Exiting log stream.
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X GET "http://127.0.0.1:7060/health" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'{"nodeHealth":"Ready","protocolsHealth":[]}'
[32mINFO    [0m src.node.waku_node:waku_node.py:282 Node protocols are initialized !!
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X GET "http://127.0.0.1:7060/debug/v1/info" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'{"listenAddresses":["/ip4/172.18.135.23/tcp/7061/p2p/16Uiu2HAm6PPePqR7DKMdMgbAC73bNcBKo12XjteJCmd4xecRDDyR","/ip4/172.18.135.23/tcp/7062/ws/p2p/16Uiu2HAm6PPePqR7DKMdMgbAC73bNcBKo12XjteJCmd4xecRDDyR"],"enrUri":"enr:-L24QD7unSogxduO7RuXptwYaoicexyFGJaFQxCUMVQHwLeGR0Ic4lI9ye2C9LOBGnp42S8W9HdKvHawu4OQMEs3fx0CgmlkgnY0gmlwhKwShxeKbXVsdGlhZGRyc5YACASsEocXBhuVAAoErBKHFwYblt0DgnJzhQADAQAAiXNlY3AyNTZrMaECotrs1X-Gc8RXS3cZbyns9X90icMF3qgBkH7_DzXk_niDdGNwghuVg3VkcIIbl4V3YWt1MgM"}'
[32mINFO    [0m src.node.waku_node:waku_node.py:287 REST service is ready !!
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:19 Docker client initialized with image quay.io/wakuorg/nwaku-pr:3244
[35mDEBUG   [0m src.node.waku_node:waku_node.py:85 WakuNode instance initialized with log path ./log/docker/store_node1_2025-01-17_10-14-57__c6cca51d-ff3f-4661-b808-8a5298fabfd0__quay.io_wakuorg_nwaku-pr:3244.log
[35mDEBUG   [0m src.node.waku_node:waku_node.py:89 Starting Node...
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:22 Attempting to create or retrieve network waku
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:25 Network waku already exists
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:108 Generated random external IP 172.18.153.42
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:101 Generated ports ['46475', '46476', '46477', '46478', '46479']
[35mDEBUG   [0m src.node.waku_node:waku_node.py:439 RLN credentials were not set
[32mINFO    [0m src.node.waku_node:waku_node.py:168 RLN credentials not set or credential store not available, starting without RLN
[35mDEBUG   [0m src.node.waku_node:waku_node.py:170 Using volumes []
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:49 docker run -i -t -p 46475:46475 -p 46476:46476 -p 46477:46477 -p 46478:46478 -p 46479:46479 quay.io/wakuorg/nwaku-pr:3244 --listen-address=0.0.0.0 --rest=true --rest-admin=true --websocket-support=true --log-level=TRACE --rest-relay-cache-capacity=100 --websocket-port=46477 --rest-port=46475 --tcp-port=46476 --discv5-udp-port=46478 --rest-address=0.0.0.0 --nat=extip:172.18.153.42 --peer-exchange=true --discv5-discovery=true --cluster-id=3 --nodekey=ac979bbdfbe9bbbeeaf04efe9cd43dc32269f80e1f7c5daa96893cf816c9c14e --shard=0 --metrics-server=true --metrics-server-address=0.0.0.0 --metrics-server-port=46479 --metrics-logging=true --discv5-bootstrap-node=enr:-L24QD7unSogxduO7RuXptwYaoicexyFGJaFQxCUMVQHwLeGR0Ic4lI9ye2C9LOBGnp42S8W9HdKvHawu4OQMEs3fx0CgmlkgnY0gmlwhKwShxeKbXVsdGlhZGRyc5YACASsEocXBhuVAAoErBKHFwYblt0DgnJzhQADAQAAiXNlY3AyNTZrMaECotrs1X-Gc8RXS3cZbyns9X90icMF3qgBkH7_DzXk_niDdGNwghuVg3VkcIIbl4V3YWt1MgM --storenode=/ip4/172.18.135.23/tcp/7061/p2p/16Uiu2HAm6PPePqR7DKMdMgbAC73bNcBKo12XjteJCmd4xecRDDyR --store=true --relay=true
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:55 docker network connect --ip 172.18.153.42 waku d476a256009572d00468c4b97181c13f967a1c21e7215fca2cfb1cdb03d7c090
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:58 Container started with ID d476a2560095. Setting up logs at ./log/docker/store_node1_2025-01-17_10-14-57__c6cca51d-ff3f-4661-b808-8a5298fabfd0__quay.io_wakuorg_nwaku-pr:3244.log
[35mDEBUG   [0m src.node.waku_node:waku_node.py:182 Started container from image quay.io/wakuorg/nwaku-pr:3244. REST: 46475
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 1 seconds
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X GET "http://127.0.0.1:46475/health" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'{"nodeHealth":"Ready","protocolsHealth":[]}'
[32mINFO    [0m src.node.waku_node:waku_node.py:282 Node protocols are initialized !!
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X GET "http://127.0.0.1:46475/debug/v1/info" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'{"listenAddresses":["/ip4/172.18.153.42/tcp/46476/p2p/16Uiu2HAmL8Ct3Cq6usCmVPxVc4DxuQ5mN8x9jeM7ymTNv9XsvJcd","/ip4/172.18.153.42/tcp/46477/ws/p2p/16Uiu2HAmL8Ct3Cq6usCmVPxVc4DxuQ5mN8x9jeM7ymTNv9XsvJcd"],"enrUri":"enr:-L24QGSVfI0wzBJqXITsZxQL3WlP85WGi0Glg_ydEIjNrYc8QAPOOiycyGkd2QX-V1n-dPRCv-Aj_8EF-pJ9vo2pEF4CgmlkgnY0gmlwhKwSmSqKbXVsdGlhZGRyc5YACASsEpkqBrWMAAoErBKZKga1jd0DgnJzhQADAQAAiXNlY3AyNTZrMaEDbvqogRoK-Y_fD4tkPl8ARmIXy1-qT1Jxw-V5FhX27x6DdGNwgrWMg3VkcIK1joV3YWt1MgM"}'
[32mINFO    [0m src.node.waku_node:waku_node.py:287 REST service is ready !!
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:46475/admin/v1/peers" -H "Content-Type: application/json" -d '["/ip4/172.18.135.23/tcp/7061/p2p/16Uiu2HAm6PPePqR7DKMdMgbAC73bNcBKo12XjteJCmd4xecRDDyR"]'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:7060/relay/v1/subscriptions" -H "Content-Type: application/json" -d '["/waku/2/rs/3/0"]'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:46475/relay/v1/subscriptions" -H "Content-Type: application/json" -d '["/waku/2/rs/3/0"]'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.steps.store:store.py:132 Relaying message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:7060/relay/v1/messages/%2Fwaku%2F2%2Frs%2F3%2F0" -H "Content-Type: application/json" -d '{"payload": "U3RvcmUgd29ya3MhIQ==", "contentTopic": "/myapp/1/latest/proto", "timestamp": '$(date +%s%N)'}'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 0.2 seconds
[35mDEBUG   [0m src.steps.store:store.py:132 Relaying message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:7060/relay/v1/messages/%2Fwaku%2F2%2Frs%2F3%2F0" -H "Content-Type: application/json" -d '{"payload": "U3RvcmUgd29ya3MhIQ==", "contentTopic": "/myapp/1/latest/proto", "timestamp": '$(date +%s%N)'}'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 0.2 seconds
[35mDEBUG   [0m src.steps.store:store.py:132 Relaying message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:7060/relay/v1/messages/%2Fwaku%2F2%2Frs%2F3%2F0" -H "Content-Type: application/json" -d '{"payload": "U3RvcmUgd29ya3MhIQ==", "contentTopic": "/myapp/1/latest/proto", "timestamp": '$(date +%s%N)'}'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 0.2 seconds
[35mDEBUG   [0m src.steps.store:store.py:132 Relaying message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:7060/relay/v1/messages/%2Fwaku%2F2%2Frs%2F3%2F0" -H "Content-Type: application/json" -d '{"payload": "U3RvcmUgd29ya3MhIQ==", "contentTopic": "/myapp/1/latest/proto", "timestamp": '$(date +%s%N)'}'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 0.2 seconds
[35mDEBUG   [0m src.steps.store:store.py:132 Relaying message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:7060/relay/v1/messages/%2Fwaku%2F2%2Frs%2F3%2F0" -H "Content-Type: application/json" -d '{"payload": "U3RvcmUgd29ya3MhIQ==", "contentTopic": "/myapp/1/latest/proto", "timestamp": '$(date +%s%N)'}'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 0.2 seconds
[35mDEBUG   [0m src.steps.store:store.py:132 Relaying message
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X POST "http://127.0.0.1:7060/relay/v1/messages/%2Fwaku%2F2%2Frs%2F3%2F0" -H "Content-Type: application/json" -d '{"payload": "U3RvcmUgd29ya3MhIQ==", "contentTopic": "/myapp/1/latest/proto", "timestamp": '$(date +%s%N)'}'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'OK'
[35mDEBUG   [0m src.libs.common:common.py:35 Sleeping for 0.2 seconds
[35mDEBUG   [0m tests.store.test_time_filter:test_time_filter.py:161 inquering stored messages with start time 0
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X GET "http://127.0.0.1:7060/store/v3/messages?includeData=True&pubsubTopic=%2Fwaku%2F2%2Frs%2F3%2F0&startTime=0&endTime=0&pageSize=20&ascending=true" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'{"requestId":"","statusCode":200,"statusDesc":"OK","messages":[{"messageHash":"JGeMihGF2HX+XCIHkaCXWO4IcQRwPYgCHmBP+zpc5nU=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108905740609792,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"5FQgBTB7yJ9gfuS4y1dpIlHdLrYG0r7+3832mM968jw=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108907740616192,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"2hYbzYL1Fz8+XlEFvD58Rw+dmkbwb9C1yxSyYo+vlb8=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108908640617984,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"uF60M3+McgNzC8BKC86WItYPnkpk61E01n1hTs9y/vo=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108908840621056,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"U1zLZpkGbMvcogMKg/YpqYFSadxfS4uReF0ITDFJ+hQ=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108910740622080,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"BWrFaIUfmhFTrCs/pQ0givziVe/9ZONCQyRtHwy2wZ8=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108918740623872,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"}]}'
[35mDEBUG   [0m tests.store.test_time_filter:test_time_filter.py:164 number of messages stored for  start time = 0 is  6
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:37 curl -v -X GET "http://127.0.0.1:46475/store/v3/messages?includeData=True&pubsubTopic=%2Fwaku%2F2%2Frs%2F3%2F0&startTime=0&endTime=0&pageSize=20&ascending=true" -H "Content-Type: application/json" -d 'None'
[32mINFO    [0m src.node.api_clients.base_client:base_client.py:22 Response status code: 200. Response content: b'{"requestId":"","statusCode":200,"statusDesc":"OK","messages":[{"messageHash":"JGeMihGF2HX+XCIHkaCXWO4IcQRwPYgCHmBP+zpc5nU=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108905740609792,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"5FQgBTB7yJ9gfuS4y1dpIlHdLrYG0r7+3832mM968jw=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108907740616192,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"2hYbzYL1Fz8+XlEFvD58Rw+dmkbwb9C1yxSyYo+vlb8=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108908640617984,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"uF60M3+McgNzC8BKC86WItYPnkpk61E01n1hTs9y/vo=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108908840621056,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"U1zLZpkGbMvcogMKg/YpqYFSadxfS4uReF0ITDFJ+hQ=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108910740622080,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"},{"messageHash":"BWrFaIUfmhFTrCs/pQ0givziVe/9ZONCQyRtHwy2wZ8=","message":{"payload":"U3RvcmUgd29ya3MhIQ==","contentTopic":"/myapp/1/latest/proto","version":0,"timestamp":1737108918740623872,"ephemeral":false},"pubsubTopic":"/waku/2/rs/3/0"}]}'
[35mDEBUG   [0m tests.store.test_time_filter:test_time_filter.py:164 number of messages stored for  start time = 0 is  6
[35mDEBUG   [0m tests.conftest:conftest.py:59 Running fixture teardown: test_setup
[35mDEBUG   [0m tests.conftest:conftest.py:83 Running fixture teardown: close_open_nodes
[35mDEBUG   [0m src.node.waku_node:waku_node.py:226 Stopping container with id 6602cf867374
[35mDEBUG   [0m src.node.waku_node:waku_node.py:233 Container stopped.
[35mDEBUG   [0m src.node.waku_node:waku_node.py:226 Stopping container with id d476a2560095
[31m[1mERROR   [0m src.node.docker_mananger:docker_mananger.py:89 Max retries reached for container 6602cf867374. Exiting log stream.
[35mDEBUG   [0m src.node.waku_node:waku_node.py:233 Container stopped.
[35mDEBUG   [0m tests.conftest:conftest.py:98 Running fixture teardown: check_waku_log_errors
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:144 No errors found in the waku logs.
[35mDEBUG   [0m src.node.docker_mananger:docker_mananger.py:144 No errors found in the waku logs.